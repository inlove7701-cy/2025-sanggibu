import streamlit as st
import google.generativeai as genai

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="2025 ìƒê¸°ë¶€ ë©”ì´íŠ¸", layout="centered")
st.title("ğŸ 2025 ìƒê¸°ë¶€ ë©”ì´íŠ¸")
st.markdown("<p style='color:#888;'>Gift for 2025 1st Grade Teachers</p>", unsafe_allow_html=True)
st.divider()

# --- [ì¤‘ìš”] API í‚¤ ì„¤ì • (ì‚¬ìš©ì ì…ë ¥ ì—†ì´ ì„œë²„ì—ì„œ ê°€ì ¸ì˜´) ---
# Streamlit Cloudì˜ Secretsì—ì„œ í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
except FileNotFoundError:
    # ë‚´ ì»´í“¨í„°ì—ì„œ í…ŒìŠ¤íŠ¸í•  ë•Œë¥¼ ìœ„í•œ ì˜ˆì™¸ ì²˜ë¦¬ (í˜¹ì€ í‚¤ ì„¤ì •ì„ ì•ˆ í–ˆì„ ë•Œ)
    st.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
    st.stop()

# 2. ì‚¬ì´ë“œë°” (í‚¤ ì…ë ¥ì°½ ì œê±°ë¨, ì˜µì…˜ë§Œ ë‚¨ìŒ)
with st.sidebar:
    st.header("ì˜µì…˜ ì„ íƒ")
    st.info("ğŸ’¡ ì„ ìƒë‹˜ë“¤ì„ ìœ„í•´ ì´ë¯¸ ì„¤ì •ì´ ì™„ë£Œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë°”ë¡œ ì‚¬ìš©í•˜ì„¸ìš”!")
    
    options = ["ìë™(ì „ì²´)", "í•™ì—…ì—­ëŸ‰(íƒêµ¬ë ¥)", "ì¸ì„±/ê³µë™ì²´(ë‚˜ëˆ”)", "ì§„ë¡œì ì„±(ì „ê³µ)", "ë°œì „ê°€ëŠ¥ì„±(ì„±ì¥)"]
    selected_mode = st.selectbox("ê°•ì¡°í•  ì˜ì—­ ì„ íƒ", options)

# 3. ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.messages.append({
        "role": "assistant", 
        "content": "ì„ ìƒë‹˜, ì•ˆë…•í•˜ì„¸ìš”! í•™ìƒì˜ ê´€ì°° ë‚´ìš©ì„ í¸í•˜ê²Œ ì ì–´ì£¼ì‹œë©´ ìƒê¸°ë¶€ ë¬¸êµ¬ë¡œ ë§Œë“¤ì–´ ë“œë¦½ë‹ˆë‹¤."
    })

# 4. ëŒ€í™” ë‚´ìš© í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 5. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ì˜ˆ: ìˆ˜í•™ ì§ˆë¬¸ì´ ë§ê³ , ì²´ìœ¡ëŒ€íšŒ ë•Œ ì‘ì›ë‹¨ì¥ì„ í•¨."):
    
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        try:
            # êµ¬ê¸€ Gemini ì„¤ì •
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel('gemini-1.5-flash')

            system_prompt = f"""
            ë‹¹ì‹ ì€ ê³ ë“±í•™êµ ìƒí™œê¸°ë¡ë¶€ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
            ì‚¬ìš©ìê°€ ì…ë ¥í•œ í•™ìƒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ [{selected_mode}] ìœ„ì£¼ë¡œ 
            í•™êµìƒí™œê¸°ë¡ë¶€ 'í–‰ë™íŠ¹ì„± ë° ì¢…í•©ì˜ê²¬'ì— ë“¤ì–´ê°ˆ ë¬¸ì¥ì„ ì‘ì„±í•˜ì„¸ìš”.
            ë¬¸ì²´ëŠ” '~í•¨', '~ì„'ìœ¼ë¡œ ëë‚˜ëŠ” ê°œì¡°ì‹ê³¼ ì„œìˆ í˜•ì„ ì ì ˆíˆ ì„ì–´ì£¼ì„¸ìš”.
            """
            
            response = model.generate_content(
                f"{system_prompt}\n\n[í•™ìƒ ì •ë³´]: {prompt}",
                stream=True
            )

            for chunk in response:
                if chunk.text:
                    full_response += chunk.text
                    message_placeholder.markdown(full_response + "â–Œ")
            
            message_placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "assistant", "content": full_response})

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
